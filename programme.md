---
layout: page
title: Programme
---

<div class="panel panel-default">
<div class="panel-body">

<p>Clarity-2023 will be a one-day workshop with a single track.

<p>There will be a session devoted to the outcomes of the 2nd Clarity Prediction Challenge.

<p> Further details of keynote talkers and panel discussion sessions are to be announced.

<h1>Keynote talks</h1>

<div class="card m-3">
  <a name="talk1"></a>

<div class="card-header">
<div class="row  align-items-center">

<div class="col-sm-3">
<img src="/clarity2023-workshop/assets/images/fei_chen.png" alt="Fei Chen" class="float-left rounded-circle" style="width:100%" />
</div>

<div class="col-sm-9">
<h1 class="lead">Fei Chen <div class="text-muted">SUSTech, China</div></h1>

<h1>Objective speech intelligibility prediction: Insights from human speech perception</h1>

<button class="btn btn-primary" style="color:white; margin: 10px; border-radius: 4px;" type="button" data-toggle="collapse" data-target="#collapseAbstractWang" aria-expanded="false" aria-controls="collapseAbstractWang">
    Abstract and Bio
  </button>

</div>
</div>
</div>

<div class="collapse" id="collapseAbstractWang">

<div class="card-body">
<h1 class="card-title">Objective speech intelligibility prediction: Insights from human speech perception</h1>

<h3>Abstract</h3>

<p>Speech intelligibility assessment plays an important role in speech and hearing studies. Designing a computational speech intelligibility model can significantly facilitate our studies, e.g., speech enhancement and speech coding. While many objective speech intelligibility prediction models are available, there are still challenges towards improving the prediction performance of intelligibility indices. Human speech perception studies provide us not only knowledge on various (e.g., acoustic, linguistic) impacts on speech understanding in different listening environments, but also insights on design a reliable objective intelligibility prediction index. In this talk, I will first introduce studies on important acoustic cues on human speech perception. Then, I will review the design of some existing intelligibility prediction models and efforts to improve their prediction power. Finally, I will briefly introduce new developments towards objective speech intelligibility prediction, e.g., machine learning and neurophysiological measurement methods.</p>

<h3>Bio</h3>

<p>To appear.</p>
</div>

</div>

</div>

<div class="card m-3">
  <a name="talk1"></a>

<div class="card-header">
<div class="row  align-items-center">

<div class="col-sm-3">
<img src="/clarity2023-workshop/assets/images/deliang_wang.png" alt="DeLiang Wang" class="float-left rounded-circle" style="width:100%" />
</div>

<div class="col-sm-9">
<h1 class="lead">DeLiang Wang <div class="text-muted">Ohio State University, US</div></h1>

<h1>Neural Spectrospatial Filtering</h1>

<button class="btn btn-primary" style="color:white; margin: 10px; border-radius: 4px;" type="button" data-toggle="collapse" data-target="#collapseAbstractWang" aria-expanded="false" aria-controls="collapseAbstractWang">
    Abstract and Bio
  </button>

</div>
</div>
</div>

<div class="collapse" id="collapseAbstractWang">

<div class="card-body">
<h1 class="card-title">Neural Spectrospatial Filtering</h1>

<h3>Abstract</h3>

<p>As the most widely-used spatial filtering approach for multi-channel signal separation,
beamforming extracts the target signal arriving from a specific direction. We present an
emerging approach based on multi-channel complex spectral mapping, which trains a deep
neural network (DNN) to directly estimate the real and imaginary spectrograms of the target
signal from those of the multi-channel noisy mixture. In this all-neural approach, the trained
DNN itself becomes a nonlinear, time-varying spectrospatial filter. How does this conceptually
simple approach perform relative to commonly-used beamforming techniques on different array
configurations and in different acoustic environments? We examine this issue systematically on
speech dereverberation, speech enhancement, and speaker separation tasks. Comprehensive
evaluations show that multi-channel complex spectral mapping achieves very competitive speech
separation results compared to beamforming for different array geometries, and reduces to
monaural complex spectral mapping in single-channel conditions, demonstrating the versatility
of this new approach for multi-channel and single-channel speech separation. In addition, such
an approach is computationally more efficient than popular mask-based beamforming. We
conclude that this neural spectrospatial filter provides a broader approach than traditional and
DNN-based beamforming.</p>

<h3>Bio</h3>

<p>DeLiang Wang received the B.S. degree and the M.S. degree from Peking (Beijing) University and the Ph.D. degree in 1991 from the University of Southern California all in computer science. Since 1991,he has been with the Department of Computer Science & Engineering and the Center for Cognitive and Brain Sciences at The Ohio State University, where he is a Professor and University Distinguished Scholar. He received the U.S. Office of Naval Research Young Investigator Award in 1996, the 2008 Helmholtz Award and 2020 Ada Lovelace Service Award from the International Neural Network Society (INNS), the 2007 Outstanding Paper Award of the IEEE ComputationalIntelligence Society and the 2019 Best Paper Award of the IEEE Signal Processing Society. He is an IEEE Fellow and ISCA Fellow. He currently serves as Co-Editor-in-Chief of Neural Networks, and a member of the INNS Board of Governors.</p>
</div>

</div>

</div>

<br/>
